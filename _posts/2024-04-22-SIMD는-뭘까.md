---
title: "SIMD는 어떤 기법일까?"
excerpt: "SIMD는 단일 CPU 명령어로 여러개의 데이터를 처리할 수 있는 기술이다.(매우 멋짐!)"

categories:
  - SIMD
tags:
  - [SIMD]

permalink: /categories/simd/SIMD는-어떤-기법일까/

toc: true
toc_sticky: true

date: 2024-04-22
last_modified_at: 2024-04-22
---

# 인트로
SIMD(Single Instruction Multiple Data)는 모던 프로세서의 핵심 기능인데, 한 번의 CPU 명령어로 여러 데이터 요소를 동시에 연산을 수행할 수 있다.
인텔 64 및 IA-32 아키텍쳐에서는 이 기술을 MMX, SSE, AVX 등 여러 명령으로 지원한다.
그리하여 인텔 64 및 IA-32 아키텍처 소프트웨어 개발자 매뉴얼을 기반으로 SIMD의 개념과 활용 방법을 간단히 살펴보려고 한다.

# SIMD 개념 이해
하나의 명령어로 다중 데이터, 즉 병렬 데이터를 연산하는 것을 말한다. 이를 벡터 연산이라고도 한다.

<img src="https://github.com/jeekpark/jeekpark.github.io/blob/main/assets/images/posts_img/simd/cpu_z_capture.png?raw=true" width="80%">

위의 사진은 CPU-Z에서 캡쳐한 CPU의 정보이다. Instructions(명령어) 항목을 보면 MMX, SSE, AVX와 같은 SIMD 명령어를 지원한다는 것을 확인할 수 있다. 이 명령어들은 인텔에서 도입한 명령어이지만 컴퓨터 산업에서 널리 표준화가 되어, 다른 프로세서 제조사(AMD 등)에서도 이를 구현하여 프로그램의 호환성을 보장하고 있다.(캡쳐본은 라이젠 CPU임에도 인텔의 SIMD명령어를 지원하고 있다)


SIMD는 주로 부동소수점 병렬연산을 위햇서 사용된다. SSE기준으로 한 명령어로 128비트 연산이 가능한데, 4개의 32비트 float이나 int32_t 자료형 데이터를 한 번에 연산할 수 있다. 

예시는 다음과 같다. SISD는 Single Instruction, Single Data의 약자로 원시적인 연산방법이다.

<img src="https://github.com/jeekpark/jeekpark.github.io/blob/main/assets/images/posts_img/simd/sisd_simd_cmp.png?raw=true">

[사진 출처](https://m.blog.naver.com/fs0608/221650925743)

기존 SISD방식은 예를 들어 4개의 float 데이터로 연산을 하면 다음과 같다.
```C
float a[4];
float b[4];

a[0] += b[0];
a[1] += b[1];
a[2] += b[2];
a[3] += b[3];
```
이런 방법은 매번 연산을 할 수 밖에 없다.
대신 SSE Intrinsic 함수를 쓰면 다음과 같다.

```C
__m128 S_a = _mm_load_ps(a);
__m128 S_b = _mm_load_ps(b);
S_a = _mm_add_ps(S_a, S_b);
_mm_store_ps(a, S_a);
```
이렇게 4번의 add 연산을 한번에 처리할 수 있다.


# 인텔 SIMD 확장

1. MMX:
- 정수 연산을 위한 64비트 SIMD
- 8개의 64비트 레지스터를 사용하여 8, 16, 32비트 정수 연산을 지원한다.

2. SSE(Streaming SIMD Extensions):
- 부동소수점 연산을 위한 128비트 SIMD.
- 4개의 단정밀도 부동소수점(float)또는 2개의 배정밀도 부동소수점(double)을 포함할 수 있는 128비트 레지스터 사용.

3. AVX(Advanced Vector Extensions):
- 부동소수점 연산을 위한 256비트 SIMD.
- 8개의 단정밀도 부동소수점(float)또는 4개의 배정밀도 부동소수점(double)을 포함할 수 있는 128비트 레지스터 사용.

# SIMD 프로그래밍을 해보려면?

SIMD를 프로그래밍으로 다룰려면(코드로) 명령어 세트에 특화된 코드를 작성해야한다. C/C++ 에서는 컴파일러의 자동 벡터화 기능을 활용하거나 인라인 어셈블리나 SIMD 라이브러리를 사용할 수 있다.

# 역사적으로 이 기술이 나온 이유
1990년대 중반, 개인용 PC나 전자기기의 보급속도는 매우 빨랐다. 개발자들은 보통 검은 화면에 콘솔창으로 개발하는 것이 일반적이겠지만, 일반 소비자들은 검은 콘솔창을 참을 수 없었을 것이다. 매킨토시나 NT계열 윈도우가 성공할 수 있었던 이유는 GUI이고 GUI의 꽃은 멀티미디어이다. '디지털 멀티미디어'가 세상을 바꾸었고, 멀티미디어 작업은 고도의 데이터 능력을 시대를 막론하고 요구해왔다. 2024년 지금도 제대로된 VR 컨텐츠를 즐길려면 12K 해상도를 요구하지만 현재의 개인 기기들은 성능이 턱없이 모자르고, 아직 올라야할 산이 많다. 이럴때 쓰는 말이 첩첩산중. 아무튼간에 이미지, 오디오, 비디오 파일 처리와 렌더링에 대한 수요가 증가했었고, 기존 스칼라 프로세싱 방식으로는 한계가 있었다. 

최초의 SIMD 기술은 1970년대 처음 개발되었다. 이 당시에는 슈퍼 컴퓨터에 적용되었었다. 이후 1996년 인텔 팬티엄 프로세서에 MMX 기술이 도입되어, 소비자 급 프로세서에서도 멀티미디어 처리 능력을 대폭 향상시킬 수 있었다. 

파급력은 매우 컸다. 특히 멀티미디어 처리 작업에서 소비자 경험이 크게 개선되었고, 현실감이 넘치는 비디오 게임을 일반 사용자에게 제공할 수 있게되었다.

# 이 기술은 중요할까?
앞서 말했듯이 아직 올라야할 산이 많이 남았다. 지금 엔비디아의 주가가 폭등하고 칩 한장에 6000만원이라는게 아직 하드웨어 단에서 해결해야할 문제가 많다는 것을 반증한다. GPT와 같은 LLM 인공지능의 활용이 대단해보일 순 있어도, 아직 효율이 좋지 못하다. 대화 30번 오가는데 500ml의 물이 소요된다는 점. 오픈AI가 인도, 아프리카의 저렴한 인건비로 말도안되는 무한 튜닝작업에 막대한 비용을 쓴다는 점. 유튜브나 뉴스에서는 GPT로 세상이 완전히 바뀔 것 처럼 이야기하지만, GPT가 스스로 6000만원짜리 칩의 효율을 개선할 수 있을까? 단순 반복 노동의 튜닝작업을 GPT 스스로 해결할 수 있을까? 아직 인간에게는 넘어야 할 산이 많다. 이러한 영역은 하드웨어의 자원을 효율적으로 이용하는 기술을 바탕으로 하나씩 정복해야할 영역이다. 이러한 영역에 도전하고 있는 기업이 엔비디아이기 때문에 주가가 폭등했듯이, 하드웨어를 이해하는 개발자는 앞으로 더욱 필요해지지 않을까 생각된다.